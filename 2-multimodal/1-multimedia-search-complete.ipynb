{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building MultiModal Search with Vector Databases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how build multi-modal search (image, audio, video) `Meta AI ImageBind` model ([multi2vec-bind](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/multi2vec-bind)).\n",
    "\n",
    "ImageBind allows us to search through text, images, audio and video files.\n",
    "\n",
    "This recipe will focus on searching through image, audio and video:\n",
    "\n",
    "* [text-to-media search](#text-to-media-search) - provide text as input to search through media\n",
    "* [image-to-media search](#image-to-media-search) - provide image as input to search through media\n",
    "* [audio-to-media search](#audio-to-media-search) - provide audio as input to search through media\n",
    "* [video-to-media search](#video-to-media-search) - provide video as input to search through media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weaviate Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageBind model is only available with local Weaviate deployments with Docker or Kubernetes.\n",
    "\n",
    "ImageBind is not supported with Weaviate Cloud Services (WCS).\n",
    "\n",
    "### Steps to deploy Weaviate locally with ImageBind\n",
    "\n",
    "1. Locate a docker compose file.\n",
    "    There is a prepared docker compose file at `/2-multimodal/docker-compose.yml`, which contains the necessary configuration to run Weaviate with `Meta's ImageBind` model.\n",
    "\n",
    "    Navigate to the multimodal folder:\n",
    "    ```\n",
    "    cd 2-multimodal\n",
    "    ```\n",
    "\n",
    "2. Run Weaviate & ImageBind with Docker Compose\n",
    "\n",
    "    > If you are new to `Docker Compose`, [here are instructions on how to install it](https://docs.docker.com/compose/install/).\n",
    "\n",
    "    To start the docker image defined in the `docker-compose.yml` file, call:\n",
    "\n",
    "    ```bash\n",
    "    docker compose up\n",
    "    ```\n",
    "    \n",
    "    > Note #1 - the first time you run the command, Docker will download a ~6GB image.\n",
    "    \n",
    "    > Note #2 – after the image is downloaded (or when we restart the image), it usually takes 30-60 seconds for the image to be ready.\n",
    "\n",
    "    > Note #3 – to shut down a running docker image, press CMD+C or CTRL+C.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "    1. The Weaviate Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --pre -I \"weaviate-client==4.4.b1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate, os\n",
    "import weaviate.classes as wvc\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `Animals` Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(client.collections.exists(\"Animals\")):\n",
    "    client.collections.delete(\"Animals\")\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"Animals\",\n",
    "    vectorizer_config=wvc.Configure.Vectorizer.multi2vec_bind(\n",
    "        audio_fields=[\"audio\"],\n",
    "        image_fields=[\"image\"],\n",
    "        video_fields=[\"video\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Helper function to convert a file to base64 representation\n",
    "def toBase64(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Images into Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "animals = client.collections.get(\"Animals\")\n",
    "\n",
    "source = os.listdir(\"./source/image/\")\n",
    "items = list()\n",
    "\n",
    "for name in source:\n",
    "    \n",
    "    print(f\"Adding {name}\")\n",
    "    \n",
    "    path = \"./source/image/\" + name\n",
    "    \n",
    "    items.append({\n",
    "        \"name\": name,            # name of the file\n",
    "        \"path\": path,            # path to the file to display result\n",
    "        \"image\": toBase64(path), # this gets vectorized - \"image\" was configured in vectorizer_config as the property holding images\n",
    "        \"mediaType\": \"image\",    # a label telling us how to display the resource \n",
    "    })\n",
    "\n",
    "    # import images in batches of 5\n",
    "    if (len(items) > 5):\n",
    "        print(f\"Inserting 5 new image objects.\")\n",
    "        animals.data.insert_many(items)\n",
    "        items.clear()\n",
    "\n",
    "# Insert any remaining items\n",
    "if (len(items) > 0):\n",
    "    print(f\"Inserting remaining ({len(items)}) items.\")\n",
    "    animals.data.insert_many(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Object count\n",
    "animals = client.collections.get(\"Animals\")\n",
    "animals.aggregate.over_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Audio Files into Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = client.collections.get(\"Animals\")\n",
    "\n",
    "source = os.listdir(\"./source/audio/\")\n",
    "items = list()\n",
    "\n",
    "for name in source:\n",
    "    print(f\"Adding {name}\")\n",
    "    \n",
    "    path = \"./source/audio/\" + name\n",
    "    items.append({\n",
    "        \"name\": name,\n",
    "        \"path\": path,\n",
    "        \"audio\": toBase64(path),\n",
    "        \"mediaType\": \"audio\"\n",
    "    })\n",
    "\n",
    "    # import images in batches of 3\n",
    "    if(len(items) == 3):\n",
    "        print(f\"Inserting 3 new audio objects.\")\n",
    "        animals.data.insert_many(items)\n",
    "        items.clear()\n",
    "\n",
    "# Insert any remaining items\n",
    "if (len(items) > 0):\n",
    "    print(f\"Inserting remaining ({len(items)}) items.\")\n",
    "    animals.data.insert_many(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.aggregate.over_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Video Files into Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = client.collections.get(\"Animals\")\n",
    "\n",
    "source = os.listdir(\"./source/video/\")\n",
    "\n",
    "for name in source:\n",
    "    print(f\"Adding {name}\")\n",
    "    \n",
    "    path = \"./source/video/\" + name\n",
    "    item = {\n",
    "        \"name\": name,\n",
    "        \"path\": path,\n",
    "        \"video\": toBase64(path),\n",
    "        \"mediaType\": \"video\"\n",
    "    }\n",
    "    \n",
    "    # insert videos one by one\n",
    "    animals.data.insert(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.aggregate.over_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.aggregate_group_by.over_all(\n",
    "    group_by=\"mediaType\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check all the media files added to the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = animals.iterator(\n",
    "    return_properties=[\"name\", \"mediaType\"],\n",
    "    # include_vector=True, # in case you want to see the vectors\n",
    ")\n",
    "\n",
    "for item in itr:\n",
    "    print(item.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Search\n",
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to display results\n",
    "import json\n",
    "from IPython.display import Image, Audio, Video\n",
    "\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "def display_media(item):\n",
    "    path = item[\"path\"]\n",
    "\n",
    "    if(item[\"mediaType\"] == \"image\"):\n",
    "        display(Image(path))\n",
    "\n",
    "    elif(item[\"mediaType\"] == \"video\"):\n",
    "        display(Video(path))\n",
    "        \n",
    "    elif(item[\"mediaType\"] == \"audio\"):\n",
    "        display(Audio(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, requests\n",
    "\n",
    "# Helper function – get base64 representation from an online image\n",
    "def url_to_base64(url):\n",
    "    image_response = requests.get(url)\n",
    "    content = image_response.content\n",
    "    return base64.b64encode(content).decode('utf-8')\n",
    "\n",
    "# Helper function - get base64 representation from a local file\n",
    "def file_to_base64(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')\n",
    "\n",
    "# Update the url and path to test\n",
    "#test_image_base64 = url_to_base64(\"https://path-to-some-online-image.jpg\")\n",
    "#test_file_base64 = file_to_base64(\"./test/meerkat.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='text-to-media-search'></a>\n",
    "### Text to Media Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = animals.query.near_text(\n",
    "    query=\"dog with stick\",\n",
    "    return_properties=['name','path','mediaType'],\n",
    "    limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in response.objects:\n",
    "    json_print(obj.properties)\n",
    "    display_media(obj.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='image-to-media-search'></a>\n",
    "### Image to Media Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./test/test-cat.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = animals.query.near_image(\n",
    "    near_image=toBase64(\"./test/test-cat.jpg\"),\n",
    "    return_properties=['name','path','mediaType'],\n",
    "    limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in response.objects:\n",
    "    json_print(obj.properties)\n",
    "    display_media(obj.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='audio-to-media-search'></a>\n",
    "### Audio to Media Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(\"./test/dog_audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = animals.query.near_audio(\n",
    "    near_audio=toBase64(\"./test/dog_audio.wav\"),\n",
    "    return_properties=['name','path','mediaType'],\n",
    "    limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in response.objects:\n",
    "    json_print(obj.properties)\n",
    "    display_media(obj.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='video-to-media-search'></a>\n",
    "### Video to Media Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"./test/test-meerkat.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = animals.query.near_video(\n",
    "    near_video=toBase64(\"./test/test-meerkat.mp4\"),\n",
    "    return_properties=['name','path','mediaType'],\n",
    "    limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in response.objects:\n",
    "    json_print(obj.properties)\n",
    "    display_media(obj.properties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
